#!/bin/bash

# æŒ‡å®šä½¿ç”¨çš„ GPU ID (ä¾‹å¦‚: 0,1)
export CUDA_VISIBLE_DEVICES=0,1

# è®¾ç½®ä½¿ç”¨çš„GPUæ•°é‡
NUM_GPUS=2

# è®¾ç½®æ•°æ®è·¯å¾„å’Œå‚æ•°
# å‡è®¾æ•°æ®åœ¨ ./Data/mt.tif
TIFF_FILE="mt.tif"
DATA_PATH="./Data"
OUTPUT_DIR="./output_jit_unet_ddp_mt"

# è®­ç»ƒå‚æ•°
BATCH_SIZE=1      # å•å¡ Batch Size (æ€» Batch Size = NUM_GPUS * BATCH_SIZE)
EPOCHS=5000000
LR=1e-4

# æ‰“å°ä¿¡æ¯
echo "ğŸš€ å¼€å§‹å¤šå¡è®­ç»ƒ (JiT-UNet)..."
echo "ä½¿ç”¨çš„ GPU æ•°é‡: $NUM_GPUS"
echo "æ•°æ®æ–‡ä»¶: $DATA_PATH/$TIFF_FILE"
echo "è¾“å‡ºç›®å½•: $OUTPUT_DIR"

# è‡ªåŠ¨æ£€æµ‹æ–­ç‚¹ç»­è®­
RESUME_ARGS=""
if [ -f "$OUTPUT_DIR/checkpoint-last.pth" ]; then
    echo "ğŸ”„ æ£€æµ‹åˆ°ä¸Šæ¬¡çš„æ£€æŸ¥ç‚¹ï¼Œå°†æ¢å¤è®­ç»ƒ..."
    RESUME_ARGS="--resume $OUTPUT_DIR"
else
    echo "ğŸ†• æœªæ£€æµ‹åˆ°æ£€æŸ¥ç‚¹ï¼Œå°†å¼€å§‹æ–°è®­ç»ƒ..."
fi

# ä½¿ç”¨ torchrun å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ
# --nproc_per_node: ä½¿ç”¨çš„ GPU æ•°é‡
# --master_port: é˜²æ­¢ç«¯å£å†²çªï¼ŒéšæœºæŒ‡å®šä¸€ä¸ª
torchrun --nproc_per_node=$NUM_GPUS --master_port=29505 main_jit_unet.py \
    --model UNet \
    --tiff_file "$TIFF_FILE" \
    --data_path "$DATA_PATH" \
    --output_dir "$OUTPUT_DIR" \
    --batch_size $BATCH_SIZE \
    --lr $LR \
    --epochs $EPOCHS \
    --use_tiff \
    --use_normalized_tiff \
    --normalize_per_image \
    --num_workers 8 \
    --save_last_freq 200 \
    --eval_freq 200 \
    --online_eval \
    --gen_bsz 1 \
    --img_size 1024 \
    --accum_iter 4 \
    $RESUME_ARGS

# è®­ç»ƒå®Œæˆåæç¤º
echo "âœ… è®­ç»ƒå®Œæˆï¼ç»“æœä¿å­˜åœ¨ $OUTPUT_DIR"
