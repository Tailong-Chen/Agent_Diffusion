#!/bin/bash

# æŒ‡å®šä½¿ç”¨çš„ GPU ID (ä¾‹å¦‚: 0,1)
export CUDA_VISIBLE_DEVICES=4,5

# è®¾ç½®ä½¿ç”¨çš„GPUæ•°é‡
NUM_GPUS=2

# è®¾ç½®æ•°æ®è·¯å¾„å’Œå‚æ•°
# å‡è®¾æ•°æ®åœ¨ ./Data/mt.tif
TIFF_FILE="Dark-mitochondrion_1024.tif"
DATA_PATH="./Data"
OUTPUT_DIR="./output_jit_unet_ddp_patch256_mitochondrion"

# è®­ç»ƒå‚æ•°
# 256x256 å›¾åƒè¾ƒå°ï¼Œå¯ä»¥å¢å¤§ Batch Size
BATCH_SIZE=8      # å•å¡ Batch Size
EPOCHS=5000000
LR=1e-4
IMG_SIZE=256       # Patch Size

# æ‰“å°ä¿¡æ¯
echo "ğŸš€ å¼€å§‹ JiT-UNet åˆ†å¸ƒå¼è®­ç»ƒ (Patch Training)"
echo "   GPUs: $NUM_GPUS (IDs: $CUDA_VISIBLE_DEVICES)"
echo "   Data: $DATA_PATH/$TIFF_FILE"
echo "   Output: $OUTPUT_DIR"
echo "   Batch Size: $BATCH_SIZE (Total: $((BATCH_SIZE * NUM_GPUS)))"
echo "   Image Size: $IMG_SIZE (Patch)"

# é¢„å¤„ç†ç»“æ„ä¿¡æ¯
echo "ğŸ” æ­£åœ¨é¢„å¤„ç†ç»“æ„ä¿¡æ¯..."
python preprocess_structure.py --tiff_path "$DATA_PATH/$TIFF_FILE" --output_path "$DATA_PATH/mt_skeletons.npy"

# æ£€æŸ¥æ˜¯å¦å­˜åœ¨ checkpoint-last.pthï¼Œå¦‚æœå­˜åœ¨åˆ™è‡ªåŠ¨æ¢å¤è®­ç»ƒ
if [ -f "$OUTPUT_DIR/checkpoint-last.pth" ]; then
    echo "ğŸ”„ æ£€æµ‹åˆ°ä¸Šæ¬¡è®­ç»ƒçš„ Checkpointï¼Œå°†æ¢å¤è®­ç»ƒ..."
    RESUME_ARGS="--resume $OUTPUT_DIR"
else
    echo "ğŸ†• æœªæ£€æµ‹åˆ° Checkpointï¼Œå°†å¼€å§‹æ–°è®­ç»ƒ..."
    RESUME_ARGS=""
fi

# è¿è¡Œ torchrun
# æ³¨æ„ï¼š--nproc_per_node å¿…é¡»ç­‰äºä½¿ç”¨çš„ GPU æ•°é‡
# è®¾ç½® num_workers=0 ä»¥é¿å…å¤šè¿›ç¨‹å¯¼è‡´çš„æ˜¾å­˜é—®é¢˜
torchrun --nproc_per_node=$NUM_GPUS --master_port=29504 main_jit_unet.py \
    --model UNet \
    --tiff_file "$TIFF_FILE" \
    --data_path "$DATA_PATH" \
    --output_dir "$OUTPUT_DIR" \
    --batch_size $BATCH_SIZE \
    --lr $LR \
    --epochs $EPOCHS \
    --use_tiff \
    --use_normalized_tiff \
    --normalize_per_image \
    --num_workers 16 \
    --save_last_freq 20 \
    --eval_freq 200 \
    --online_eval \
    --gen_bsz 8 \
    --img_size $IMG_SIZE \
    --accum_iter 1 \
    $RESUME_ARGS

# è®­ç»ƒå®Œæˆåæç¤º
echo "âœ… è®­ç»ƒå®Œæˆï¼ç»“æœä¿å­˜åœ¨ $OUTPUT_DIR"
