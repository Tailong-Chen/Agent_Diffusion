# TIFFå †æ ˆLDMè®­ç»ƒæŒ‡å—

å®Œæ•´çš„è®­ç»ƒè„šæœ¬ï¼Œç”¨äºä»TIFFå †æ ˆæ•°æ®è®­ç»ƒæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰ã€‚

---

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒè¦æ±‚](#ç¯å¢ƒè¦æ±‚)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [è¯¦ç»†ä½¿ç”¨](#è¯¦ç»†ä½¿ç”¨)
- [è„šæœ¬è¯´æ˜](#è„šæœ¬è¯´æ˜)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ”§ ç¯å¢ƒè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- **GPU**: NVIDIA GPU with CUDA support
- **æ˜¾å­˜**: è‡³å°‘32GB (æ¨èç”¨äº1024Ã—1024)
- **å†…å­˜**: è‡³å°‘32GB RAM
- **ç¡¬ç›˜**: æ ¹æ®æ•°æ®é›†å¤§å°ï¼Œå»ºè®®è‡³å°‘50GBç©ºé—²ç©ºé—´

### è½¯ä»¶ä¾èµ–

```bash
# æ ¸å¿ƒä¾èµ–
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# MONAIå’ŒGenerative Models
pip install monai
pip install git+https://github.com/Project-MONAI/GenerativeModels.git

# æ•°æ®å¤„ç†
pip install tifffile  # æ¨è
pip install pillow

# å¯è§†åŒ–
pip install matplotlib
pip install tqdm
```

**æˆ–è€…ä½¿ç”¨requirementsæ–‡ä»¶**:

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n ldm_train python=3.10
conda activate ldm_train

# å®‰è£…ä¾èµ–
pip install -r requirements_tiff_ldm.txt
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ•°æ®

ç¡®ä¿æ‚¨çš„TIFFå †æ ˆæ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼š
- æ–‡ä»¶æ ¼å¼: `.tif` æˆ– `.tiff`
- å›¾åƒå½¢çŠ¶: (N, H, W) æˆ– (N, H, W, C)
- N: å›¾åƒæ•°é‡ï¼ˆå‡ åå¼ ï¼‰
- H, W: å›¾åƒå°ºå¯¸ï¼ˆ1024Ã—1024ï¼‰
- æ•°æ®ç±»å‹: uint8, uint16, æˆ– float32

**ç¤ºä¾‹TIFFæ–‡ä»¶ç»“æ„**:
```
your_data.tif
â”œâ”€â”€ å›¾åƒ1 (1024Ã—1024)
â”œâ”€â”€ å›¾åƒ2 (1024Ã—1024)
â”œâ”€â”€ å›¾åƒ3 (1024Ã—1024)
â””â”€â”€ ... (æ›´å¤šå›¾åƒ)
```

### 2. è®­ç»ƒæ¨¡å‹

**å®Œæ•´è®­ç»ƒ** (AutoEncoder + Diffusion):

```bash
python train_tiff_ldm.py \
    --tiff_path ./data/your_data.tif \
    --output_dir ./output_ldm \
    --image_size 1024 \
    --batch_size 2
```

**åˆ†æ­¥è®­ç»ƒ** (æ¨èï¼Œæ›´çµæ´»):

```bash
# æ­¥éª¤1: åªè®­ç»ƒAutoEncoder
python train_tiff_ldm.py \
    --tiff_path ./data/your_data.tif \
    --output_dir ./output_ldm \
    --image_size 1024 \
    --skip_diffusion

# æ­¥éª¤2: è®­ç»ƒDiffusion Model
python train_tiff_ldm.py \
    --tiff_path ./data/your_data.tif \
    --output_dir ./output_ldm \
    --image_size 1024 \
    --skip_autoencoder \
    --autoencoder_checkpoint ./output_ldm/checkpoints/autoencoder_epoch_150.pth
```

### 3. ç”Ÿæˆæ–°æ ·æœ¬

```bash
python generate_samples.py \
    --checkpoint ./output_ldm/checkpoints/diffusion_epoch_250.pth \
    --output_dir ./generated \
    --num_samples 20 \
    --num_inference_steps 1000
```

---

## ğŸ“– è¯¦ç»†ä½¿ç”¨

### è®­ç»ƒè„šæœ¬å‚æ•°è¯´æ˜

#### `train_tiff_ldm.py`

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--tiff_path` | str | **å¿…éœ€** | TIFFå †æ ˆæ–‡ä»¶è·¯å¾„ |
| `--output_dir` | str | `./output_ldm` | è¾“å‡ºç›®å½• |
| `--image_size` | int | `1024` | å›¾åƒå°ºå¯¸ |
| `--max_images` | int | `None` | æœ€å¤šä½¿ç”¨å¤šå°‘å¼ å›¾åƒ |
| `--batch_size` | int | `None` | æ‰¹æ¬¡å¤§å°ï¼ˆè‡ªåŠ¨æ¨èï¼‰|
| `--skip_autoencoder` | flag | `False` | è·³è¿‡AutoEncoderè®­ç»ƒ |
| `--skip_diffusion` | flag | `False` | è·³è¿‡Diffusionè®­ç»ƒ |
| `--autoencoder_checkpoint` | str | `None` | AutoEncoder checkpoint |
| `--seed` | int | `42` | éšæœºç§å­ |

#### ä½¿ç”¨ç¤ºä¾‹

**ç¤ºä¾‹1: ä½¿ç”¨è¾ƒå°çš„å›¾åƒå°ºå¯¸**

å¦‚æœæ˜¾å­˜ä¸å¤Ÿï¼Œå¯ä»¥é™ä½åˆ†è¾¨ç‡ï¼š

```bash
python train_tiff_ldm.py \
    --tiff_path ./data/your_data.tif \
    --output_dir ./output_512 \
    --image_size 512 \
    --batch_size 6
```

**ç¤ºä¾‹2: åªä½¿ç”¨éƒ¨åˆ†æ•°æ®å¿«é€Ÿæµ‹è¯•**

```bash
python train_tiff_ldm.py \
    --tiff_path ./data/your_data.tif \
    --output_dir ./output_test \
    --max_images 20 \
    --image_size 512
```

**ç¤ºä¾‹3: æ¢å¤è®­ç»ƒ**

å¦‚æœè®­ç»ƒä¸­æ–­ï¼Œå¯ä»¥åŠ è½½checkpointç»§ç»­ï¼š

```bash
python train_tiff_ldm.py \
    --tiff_path ./data/your_data.tif \
    --output_dir ./output_ldm \
    --autoencoder_checkpoint ./output_ldm/checkpoints/autoencoder_epoch_100.pth
```

### ç”Ÿæˆè„šæœ¬å‚æ•°è¯´æ˜

#### `generate_samples.py`

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--checkpoint` | str | **å¿…éœ€** | æ¨¡å‹checkpointè·¯å¾„ |
| `--output_dir` | str | `./generated_samples` | è¾“å‡ºç›®å½• |
| `--num_samples` | int | `10` | ç”Ÿæˆæ ·æœ¬æ•°é‡ |
| `--num_inference_steps` | int | `1000` | æ¨ç†æ­¥æ•°ï¼ˆè¶Šå¤šè¶Šå¥½ï¼‰|
| `--batch_size` | int | `1` | æ‰¹æ¬¡å¤§å° |
| `--save_intermediates` | flag | `False` | ä¿å­˜å»å™ªä¸­é—´æ­¥éª¤ |
| `--seed` | int | `42` | éšæœºç§å­ |

#### ä½¿ç”¨ç¤ºä¾‹

**å¿«é€Ÿç”Ÿæˆ** (å‡å°‘æ¨ç†æ­¥æ•°):

```bash
python generate_samples.py \
    --checkpoint ./output_ldm/checkpoints/diffusion_epoch_250.pth \
    --num_samples 10 \
    --num_inference_steps 50
```

**é«˜è´¨é‡ç”Ÿæˆ** (æ›´å¤šæ¨ç†æ­¥æ•°):

```bash
python generate_samples.py \
    --checkpoint ./output_ldm/checkpoints/diffusion_epoch_250.pth \
    --num_samples 5 \
    --num_inference_steps 1000
```

**å¯è§†åŒ–å»å™ªè¿‡ç¨‹**:

```bash
python generate_samples.py \
    --checkpoint ./output_ldm/checkpoints/diffusion_epoch_250.pth \
    --num_samples 1 \
    --save_intermediates
```

---

## ğŸ“ è„šæœ¬è¯´æ˜

### 1. `train_tiff_ldm.py` - ä¸»è®­ç»ƒè„šæœ¬

**åŠŸèƒ½**:
- è‡ªåŠ¨è¯»å–TIFFå †æ ˆæ•°æ®
- è®­ç»ƒAutoencoderKLï¼ˆç¬¬ä¸€é˜¶æ®µï¼‰
- è®­ç»ƒDiffusion Modelï¼ˆç¬¬äºŒé˜¶æ®µï¼‰
- è‡ªåŠ¨ä¿å­˜checkpointså’Œæ ·æœ¬
- ç»˜åˆ¶è®­ç»ƒæ›²çº¿

**è¾“å‡ºç»“æ„**:
```
output_ldm/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ autoencoder_epoch_20.pth
â”‚   â”œâ”€â”€ autoencoder_epoch_40.pth
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ diffusion_epoch_40.pth
â”‚   â””â”€â”€ diffusion_epoch_250.pth
â”œâ”€â”€ samples/
â”‚   â”œâ”€â”€ autoencoder_reconstruction_epoch_20.png
â”‚   â”œâ”€â”€ generated_epoch_40.png
â”‚   â””â”€â”€ ...
â””â”€â”€ training_history.png
```

**å…³é”®ç‰¹æ€§**:
- âœ… è‡ªåŠ¨æ•°æ®å½’ä¸€åŒ–
- âœ… è‡ªåŠ¨è®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†ï¼ˆ85%/15%ï¼‰
- âœ… æ··åˆç²¾åº¦è®­ç»ƒ
- âœ… æ¢¯åº¦ç´¯ç§¯ï¼ˆé’ˆå¯¹å¤§å›¾åƒï¼‰
- âœ… æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
- âœ… å®šæœŸä¿å­˜checkpoint
- âœ… å®æ—¶æ˜¾å­˜ç›‘æ§

### 2. `generate_samples.py` - æ¨ç†ç”Ÿæˆè„šæœ¬

**åŠŸèƒ½**:
- åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
- ä»éšæœºå™ªå£°ç”Ÿæˆæ–°å›¾åƒ
- ä¿å­˜ä¸ºPNGå’ŒTIFFæ ¼å¼
- åˆ›å»ºæ ·æœ¬ç½‘æ ¼å¯è§†åŒ–
- å¯é€‰ï¼šå¯è§†åŒ–å»å™ªè¿‡ç¨‹

**è¾“å‡ºç»“æ„**:
```
generated_samples/
â”œâ”€â”€ sample_0001.png
â”œâ”€â”€ sample_0002.png
â”œâ”€â”€ ...
â”œâ”€â”€ sample_grid.png
â”œâ”€â”€ sample_stack.tif
â””â”€â”€ denoising_process.png (å¦‚æœä½¿ç”¨--save_intermediates)
```

### 3. é…ç½®æ–‡ä»¶

#### `config_512.py` - 512Ã—512é…ç½®
- é€‚åˆ32GBæ˜¾å­˜
- æ‰¹æ¬¡å¤§å°: 6
- è®­ç»ƒæ—¶é—´: 10-15å°æ—¶

#### `config_1024_optimized.py` - 1024Ã—1024ä¼˜åŒ–é…ç½®
- é’ˆå¯¹32GBæ˜¾å­˜ä¼˜åŒ–
- æ‰¹æ¬¡å¤§å°: 2
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
- è®­ç»ƒæ—¶é—´: 2-4å¤©

---

## âš™ï¸ è®­ç»ƒé…ç½®è¯¦è§£

### ç½‘ç»œæ¶æ„

#### AutoencoderKL
```python
è¾“å…¥: (B, 1, 1024, 1024)  # æ‰¹æ¬¡å¤§å°, é€šé“, é«˜, å®½
      â†“ Encoder (3å±‚ä¸‹é‡‡æ ·)
æ½œåœ¨ç©ºé—´: (B, 4, 128, 128)  # ä¸‹é‡‡æ ·8å€
      â†“ Decoder (3å±‚ä¸Šé‡‡æ ·)
è¾“å‡º: (B, 1, 1024, 1024)
```

**æŸå¤±å‡½æ•°**:
- L1é‡å»ºæŸå¤±
- æ„ŸçŸ¥æŸå¤± (AlexNet)
- KLæ•£åº¦æŸå¤±
- å¯¹æŠ—æŸå¤± (PatchGAN)

#### DiffusionModelUNet
```python
è¾“å…¥: (B, 4, 128, 128)  # åœ¨æ½œåœ¨ç©ºé—´æ“ä½œ
      â†“ UNet (å«æ³¨æ„åŠ›æœºåˆ¶)
è¾“å‡º: (B, 4, 128, 128)  # é¢„æµ‹å™ªå£°
```

### è®­ç»ƒè¶…å‚æ•°

| é˜¶æ®µ | å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **AutoEncoder** | Epochs | 150 | å¯æ ¹æ®æ•°æ®é‡è°ƒæ•´ |
| | Learning Rate (G) | 5e-5 | Generatorå­¦ä¹ ç‡ |
| | Learning Rate (D) | 2e-4 | Discriminatorå­¦ä¹ ç‡ |
| | Warm-up Epochs | 15 | é¢„çƒ­æœŸï¼Œä¸ä½¿ç”¨å¯¹æŠ—æŸå¤± |
| | KL Weight | 1e-6 | KLæ•£åº¦æƒé‡ |
| | Perceptual Weight | 0.001 | æ„ŸçŸ¥æŸå¤±æƒé‡ |
| | Adversarial Weight | 0.01 | å¯¹æŠ—æŸå¤±æƒé‡ |
| **Diffusion** | Epochs | 250 | å¯æ ¹æ®æ•°æ®é‡è°ƒæ•´ |
| | Learning Rate | 5e-5 | UNetå­¦ä¹ ç‡ |
| | Timesteps | 1000 | è®­ç»ƒæ—¶çš„æ—¶é—´æ­¥æ•° |
| | Schedule | scaled_linear_beta | å™ªå£°è°ƒåº¦å™¨ |

### æ˜¾å­˜ä¼˜åŒ–ç­–ç•¥

é’ˆå¯¹32GBæ˜¾å­˜çš„ä¼˜åŒ–ï¼ˆ1024Ã—1024ï¼‰ï¼š

1. **æ··åˆç²¾åº¦è®­ç»ƒ** (FP16)
   - èŠ‚çœ ~50% æ˜¾å­˜
   - å·²è‡ªåŠ¨å¯ç”¨

2. **æ¢¯åº¦ç´¯ç§¯** (4æ­¥)
   - ç­‰æ•ˆæ‰¹æ¬¡å¤§å° = 2 Ã— 4 = 8
   - ä¸å¢åŠ æ˜¾å­˜æ¶ˆè€—

3. **æ¢¯åº¦è£å‰ª**
   - æœ€å¤§æ¢¯åº¦èŒƒæ•°: 1.0
   - é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸

4. **å®šæœŸæ¸…ç†ç¼“å­˜**
   - æ¯50æ­¥æ¸…ç†ä¸€æ¬¡
   - é‡Šæ”¾æœªä½¿ç”¨çš„æ˜¾å­˜

---

## ğŸ“Š é¢„æœŸç»“æœ

### è®­ç»ƒæ—¶é—´ï¼ˆ32GBæ˜¾å­˜ï¼‰

| åˆ†è¾¨ç‡ | AutoEncoder | Diffusion | æ€»è®¡ |
|--------|-------------|-----------|------|
| 512Ã—512 | ~4-5å°æ—¶ | ~6-8å°æ—¶ | **10-13å°æ—¶** |
| 1024Ã—1024 | ~12-18å°æ—¶ | ~24-36å°æ—¶ | **2-3å¤©** |

### æ˜¾å­˜ä½¿ç”¨

| é˜¶æ®µ | 512Ã—512 | 1024Ã—1024 |
|------|---------|-----------|
| AutoEncoderè®­ç»ƒ | 18-22 GB | 28-32 GB |
| Diffusionè®­ç»ƒ | 20-24 GB | 28-30 GB |
| æ¨ç†ç”Ÿæˆ | 8-12 GB | 15-20 GB |

### Lossé¢„æœŸå€¼

**AutoEncoderKL**:
- Reconstruction Loss: åº”é™è‡³ < 0.02 (512) æˆ– < 0.03 (1024)
- Generator Loss: åº”ç¨³å®šåœ¨ 0.2-0.3
- Discriminator Loss: åº”ç¨³å®šåœ¨ 0.2-0.3

**Diffusion Model**:
- MSE Loss: åº”æ”¶æ•›è‡³ 0.10-0.15
- éªŒè¯Loss: åº”ä¸è®­ç»ƒLossæ¥è¿‘

---

## â“ å¸¸è§é—®é¢˜

### Q1: æ˜¾å­˜ä¸è¶³ (Out of Memory)

**ç—‡çŠ¶**: `CUDA out of memory` é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ–¹æ¡ˆ1: å‡å°æ‰¹æ¬¡å¤§å°
--batch_size 1

# æ–¹æ¡ˆ2: é™ä½å›¾åƒåˆ†è¾¨ç‡
--image_size 512

# æ–¹æ¡ˆ3: ä½¿ç”¨æ›´å¤šæ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆè„šæœ¬å·²è‡ªåŠ¨å¤„ç†ï¼‰
```

### Q2: TIFFæ–‡ä»¶è¯»å–å¤±è´¥

**ç—‡çŠ¶**: æ— æ³•åŠ è½½TIFFæ–‡ä»¶

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å®‰è£…tifffile
pip install tifffile

# å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œæ£€æŸ¥TIFFæ–‡ä»¶æ ¼å¼
python -c "import tifffile; print(tifffile.imread('your_data.tif').shape)"
```

### Q3: è®­ç»ƒé€Ÿåº¦å¤ªæ…¢

**å¯èƒ½åŸå› **:
1. æ•°æ®åŠ è½½ç“¶é¢ˆ
2. å›¾åƒå°ºå¯¸å¤ªå¤§
3. æ¨ç†æ­¥æ•°å¤ªå¤š

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å‡å°‘num_workers
# åœ¨è„šæœ¬ä¸­ä¿®æ”¹: config.num_workers = 2

# ä½¿ç”¨è¾ƒå°çš„éªŒè¯é—´éš”
# å‡å°‘éªŒè¯é¢‘ç‡ä»¥åŠ å¿«è®­ç»ƒ

# ä½¿ç”¨æ›´å¿«çš„é‡‡æ ·ï¼ˆä»…æ¨ç†æ—¶ï¼‰
--num_inference_steps 50  # è€Œä¸æ˜¯1000
```

### Q4: ç”Ÿæˆçš„å›¾åƒè´¨é‡ä¸ä½³

**å¯èƒ½åŸå› **:
1. è®­ç»ƒä¸å……åˆ†
2. æ•°æ®é‡å¤ªå°‘
3. å­¦ä¹ ç‡ä¸åˆé€‚

**è§£å†³æ–¹æ¡ˆ**:
1. **å¢åŠ è®­ç»ƒè½®æ•°**:
   ```bash
   # åœ¨è„šæœ¬ä¸­ä¿®æ”¹epochsé…ç½®
   ```

2. **æ£€æŸ¥æ•°æ®è´¨é‡**:
   - ç¡®ä¿TIFFå›¾åƒè´¨é‡è‰¯å¥½
   - ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®é‡ï¼ˆè‡³å°‘30-50å¼ ï¼‰

3. **è°ƒæ•´å­¦ä¹ ç‡**:
   - å¦‚æœLossä¸ä¸‹é™ï¼Œå°è¯•å¢å¤§å­¦ä¹ ç‡
   - å¦‚æœLosséœ‡è¡ï¼Œå°è¯•å‡å°å­¦ä¹ ç‡

### Q5: å¦‚ä½•æ¢å¤ä¸­æ–­çš„è®­ç»ƒï¼Ÿ

è®­ç»ƒè„šæœ¬ä¼šè‡ªåŠ¨ä¿å­˜checkpointï¼Œæ‚¨å¯ä»¥ï¼š

```bash
# åŠ è½½æœ€æ–°çš„checkpointç»§ç»­è®­ç»ƒ
python train_tiff_ldm.py \
    --tiff_path ./data/your_data.tif \
    --output_dir ./output_ldm \
    --autoencoder_checkpoint ./output_ldm/checkpoints/autoencoder_epoch_100.pth
```

### Q6: ç”Ÿæˆçš„å›¾åƒä¸è®­ç»ƒæ•°æ®é£æ ¼ä¸ç¬¦

**å¯èƒ½åŸå› **:
- Diffusionæ¨¡å‹è®­ç»ƒä¸å……åˆ†
- Scaling factorè®¡ç®—ä¸å‡†ç¡®

**è§£å†³æ–¹æ¡ˆ**:
1. å¢åŠ Diffusionè®­ç»ƒè½®æ•°
2. ä½¿ç”¨æ›´å¤šçš„æ¨ç†æ­¥æ•°ç”Ÿæˆ
3. æ£€æŸ¥AutoEncoderé‡å»ºè´¨é‡

---

## ğŸ“ˆ ç›‘æ§è®­ç»ƒè¿›åº¦

### 1. å®æ—¶ç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæ˜¾ç¤ºï¼š
```
Epoch 50/150: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:15<00:00]
recons: 0.0234  gen: 0.255  disc: 0.254  mem: 29.3GB
```

### 2. æŸ¥çœ‹è®­ç»ƒæ›²çº¿

```bash
# æŸ¥çœ‹ç”Ÿæˆçš„è®­ç»ƒå†å²å›¾
open output_ldm/training_history.png
```

### 3. æ£€æŸ¥ä¸­é—´æ ·æœ¬

```bash
# AutoEncoderé‡å»ºæ ·æœ¬
ls output_ldm/samples/autoencoder_reconstruction_*.png

# Diffusionç”Ÿæˆæ ·æœ¬
ls output_ldm/samples/generated_epoch_*.png
```

### 4. ä½¿ç”¨TensorBoardï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦æ›´è¯¦ç»†çš„ç›‘æ§ï¼Œå¯ä»¥ä¿®æ”¹è„šæœ¬æ·»åŠ TensorBoardæ”¯æŒã€‚

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æ•°æ®å‡†å¤‡
- âœ… ç¡®ä¿å›¾åƒè´¨é‡é«˜
- âœ… å›¾åƒæ•°é‡è‡³å°‘30-50å¼ 
- âœ… å›¾åƒå†…å®¹åº”è¯¥ç›¸ä¼¼ï¼ˆåŒä¸€ç±»å‹/é£æ ¼ï¼‰
- âœ… æ•°æ®é¢„å¤„ç†è¦ä¸€è‡´

### 2. è®­ç»ƒç­–ç•¥
- âœ… å…ˆç”¨å°åˆ†è¾¨ç‡ï¼ˆ512ï¼‰æµ‹è¯•
- âœ… ä½¿ç”¨åˆ†æ­¥è®­ç»ƒï¼ˆå…ˆAEåDiffusionï¼‰
- âœ… å®šæœŸæ£€æŸ¥æ ·æœ¬è´¨é‡
- âœ… ä¿ç•™å¤šä¸ªcheckpoint

### 3. ç”Ÿæˆç­–ç•¥
- âœ… ä½¿ç”¨å……è¶³çš„æ¨ç†æ­¥æ•°ï¼ˆ1000æ­¥ï¼‰
- âœ… ç”Ÿæˆå¤šä¸ªæ ·æœ¬é€‰æ‹©æœ€ä½³
- âœ… å¯ä»¥è°ƒæ•´éšæœºç§å­è·å¾—ä¸åŒç»“æœ

### 4. æ˜¾å­˜ç®¡ç†
- âœ… ç›‘æ§æ˜¾å­˜ä½¿ç”¨
- âœ… é€‚å½“è°ƒæ•´batch_size
- âœ… å…³é—­ä¸å¿…è¦çš„è¿›ç¨‹

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [MONAIæ–‡æ¡£](https://docs.monai.io/)
- [MONAI GenerativeModels](https://github.com/Project-MONAI/GenerativeModels)
- [Latent Diffusion Modelsè®ºæ–‡](https://arxiv.org/abs/2112.10752)
- [åŸå§‹æ•™ç¨‹](./2d_ldm_tutorial.ipynb)

---

## ğŸ’¡ æç¤ºä¸æŠ€å·§

### å¿«é€Ÿæµ‹è¯•æµç¨‹

```bash
# 1. ä½¿ç”¨å°‘é‡æ•°æ®å’Œå°åˆ†è¾¨ç‡å¿«é€Ÿæµ‹è¯•ï¼ˆ~1å°æ—¶ï¼‰
python train_tiff_ldm.py \
    --tiff_path ./data/your_data.tif \
    --output_dir ./test_run \
    --max_images 20 \
    --image_size 256 \
    --batch_size 8

# 2. å¦‚æœæµ‹è¯•æˆåŠŸï¼Œå†è¿›è¡Œå®Œæ•´è®­ç»ƒ
python train_tiff_ldm.py \
    --tiff_path ./data/your_data.tif \
    --output_dir ./full_run \
    --image_size 1024 \
    --batch_size 2
```

### æ¸è¿›å¼è®­ç»ƒï¼ˆæ¨èç”¨äº1024ï¼‰

```bash
# é˜¶æ®µ1: 256Ã—256 (å¿«é€Ÿé¢„çƒ­)
python train_tiff_ldm.py \
    --tiff_path ./data/your_data.tif \
    --output_dir ./progressive_256 \
    --image_size 256

# é˜¶æ®µ2: 512Ã—512 (ä¸­ç­‰åˆ†è¾¨ç‡)
python train_tiff_ldm.py \
    --tiff_path ./data/your_data.tif \
    --output_dir ./progressive_512 \
    --image_size 512

# é˜¶æ®µ3: 1024Ã—1024 (æœ€ç»ˆåˆ†è¾¨ç‡)
python train_tiff_ldm.py \
    --tiff_path ./data/your_data.tif \
    --output_dir ./progressive_1024 \
    --image_size 1024 \
    --autoencoder_checkpoint ./progressive_512/checkpoints/autoencoder_epoch_150.pth
```

---

## ğŸ†˜ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. æ£€æŸ¥æœ¬æ–‡æ¡£çš„"å¸¸è§é—®é¢˜"éƒ¨åˆ†
2. æŸ¥çœ‹è„šæœ¬è¾“å‡ºçš„é”™è¯¯ä¿¡æ¯
3. æ£€æŸ¥æ˜¾å­˜ä½¿ç”¨æƒ…å†µ
4. ç¡®è®¤æ•°æ®æ ¼å¼æ­£ç¡®

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€**

