"""
DDPå¤šå¡é‡‡æ ·è„šæœ¬
æ”¯æŒä½¿ç”¨ torchrun è¿›è¡Œå¹¶è¡Œé‡‡æ ·ã€‚
æ¯ä¸ª GPU è´Ÿè´£ç”Ÿæˆä¸€éƒ¨åˆ†æ ·æœ¬ã€‚
"""

import argparse
import torch
import numpy as np
import tifffile
from pathlib import Path
from tqdm import tqdm
import os
import torch.distributed as dist
from monai.utils import set_determinism
from generative.inferers import DiffusionInferer
from generative.networks.nets import DiffusionModelUNet
from generative.networks.schedulers import DDPMScheduler

def setup_ddp():
    """åˆå§‹åŒ–DDP"""
    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:
        rank = int(os.environ['RANK'])
        world_size = int(os.environ['WORLD_SIZE'])
        local_rank = int(os.environ['LOCAL_RANK'])
        dist.init_process_group(backend='nccl')
        torch.cuda.set_device(local_rank)
    else:
        # å•å¡æ¨¡å¼
        rank = 0
        world_size = 1
        local_rank = 0
        if torch.cuda.is_available():
            torch.cuda.set_device(0)
    
    return rank, world_size, local_rank

def cleanup_ddp():
    if dist.is_initialized():
        dist.destroy_process_group()

def find_best_checkpoint(model_dir):
    """æŸ¥æ‰¾æœ€ä½³æˆ–æœ€æ–°çš„checkpoint"""
    model_dir = Path(model_dir)
    ckpt_dir = model_dir / "checkpoints"
    
    if not ckpt_dir.exists():
        ckpt_dir = model_dir
    
    best_model = ckpt_dir / "best_model.pth"
    if best_model.exists():
        return best_model
    
    ckpts = list(ckpt_dir.glob("model_epoch_*.pth"))
    if not ckpts:
        raise FileNotFoundError(f"No checkpoints found in {model_dir}")
    
    def get_epoch(p):
        try:
            return int(p.stem.split("_")[-1])
        except:
            return 0
            
    latest_ckpt = sorted(ckpts, key=get_epoch)[-1]
    return latest_ckpt

def sample_ddpm_ddp(
    model_dir,
    output_dir,
    image_size=512,
    total_samples=100,
    batch_size=4,
    num_inference_steps=1000,
    seed=42
):
    # 1. DDP Setup
    rank, world_size, local_rank = setup_ddp()
    device = torch.device(f"cuda:{local_rank}" if torch.cuda.is_available() else "cpu")
    
    if rank == 0:
        print(f"ğŸš€ Starting DDP Sampling with {world_size} GPUs")
        print(f"   Total samples: {total_samples}")
        print(f"   Per GPU samples: {total_samples // world_size}")
    
    # è®¾ç½®éšæœºç§å­ (æ¯ä¸ªrankä¸åŒï¼Œä¿è¯ç”Ÿæˆå¤šæ ·æ€§)
    set_determinism(seed + rank)
    
    model_dir = Path(model_dir)
    if output_dir is None:
        output_dir = model_dir / "generated_samples"
    else:
        output_dir = Path(output_dir)
    
    if rank == 0:
        output_dir.mkdir(parents=True, exist_ok=True)
    
    # ç¡®ä¿ç›®å½•å·²åˆ›å»º
    if world_size > 1:
        dist.barrier()

    # ============================================
    # 2. åˆå§‹åŒ–æ¨¡å‹
    # ============================================
    if image_size >= 512:
        num_channels = (128, 256, 512)
        attention_levels = (False, False, False)
        num_head_channels = 512
    else:
        num_channels = (128, 256, 256)
        attention_levels = (False, True, True)
        num_head_channels = 256
    
    unet = DiffusionModelUNet(
        spatial_dims=2,
        in_channels=1,
        out_channels=1,
        num_res_blocks=2,
        num_channels=num_channels,
        attention_levels=attention_levels,
        num_head_channels=num_head_channels,
    ).to(device)
    
    # åŠ è½½æƒé‡
    ckpt_path = find_best_checkpoint(model_dir)
    if rank == 0:
        print(f"   Loading checkpoint: {ckpt_path}")
        
    ckpt = torch.load(str(ckpt_path), map_location=device)
    if 'model_state_dict' in ckpt:
        unet.load_state_dict(ckpt['model_state_dict'])
    else:
        unet.load_state_dict(ckpt)
    
    unet.eval()
    
    # ============================================
    # 3. åˆ†é…ä»»åŠ¡
    # ============================================
    # è®¡ç®—å½“å‰rankéœ€è¦ç”Ÿæˆçš„æ•°é‡
    samples_per_rank = total_samples // world_size
    remainder = total_samples % world_size
    if rank < remainder:
        samples_per_rank += 1
        
    # è®¡ç®—å…¨å±€èµ·å§‹ç´¢å¼• (ç”¨äºå‘½å)
    # ç®€å•çš„åšæ³•ï¼šæ¯ä¸ªrankç”Ÿæˆè‡ªå·±çš„ï¼Œå‘½åå¸¦rank_idï¼Œæˆ–è€…è®¡ç®—offset
    # ä¸ºäº†ç®€å•ä¸”ä¸å†²çªï¼Œæ–‡ä»¶åæ ¼å¼: sample_rank{rank}_{idx}.tif
    
    scheduler = DDPMScheduler(num_train_timesteps=1000)
    inferer = DiffusionInferer(scheduler)
    
    num_batches = (samples_per_rank + batch_size - 1) // batch_size
    
    if rank == 0:
        print(f"   Start sampling...")

    with torch.no_grad():
        for i in range(num_batches):
            current_batch_size = min(batch_size, samples_per_rank - i * batch_size)
            
            noise = torch.randn((current_batch_size, 1, image_size, image_size)).to(device)
            scheduler.set_timesteps(num_inference_steps=num_inference_steps)
            
            image = noise
            
            # åªæœ‰rank 0 æ˜¾ç¤ºè¿›åº¦æ¡ï¼Œæˆ–è€…æ¯ä¸ªrankéƒ½æ˜¾ç¤ºä½†æè¿°ä¸åŒ
            if rank == 0:
                iterator = tqdm(scheduler.timesteps, desc=f"Rank {rank} Batch {i+1}/{num_batches}")
            else:
                iterator = scheduler.timesteps
                
            for t in iterator:
                model_output = unet(
                    x=image,
                    timesteps=torch.Tensor((t,)).to(device).long()
                )
                step_result = scheduler.step(model_output, t, image)
                
                if isinstance(step_result, tuple):
                    image = step_result[0]
                else:
                    image = step_result.prev_sample
            
            # ä¿å­˜å›¾åƒ
            for j in range(current_batch_size):
                # å”¯ä¸€ID
                local_idx = i * batch_size + j
                global_idx = rank * 10000 + local_idx # ç®€å•é¿å…å†²çª
                
                img_data = image[j, 0].cpu().numpy().astype(np.float32)
                
                # æ–‡ä»¶å: sample_r{rank}_{idx}.tif
                save_path = output_dir / f"sample_r{rank}_{local_idx:04d}.tif"
                tifffile.imwrite(save_path, img_data)
    
    if world_size > 1:
        dist.barrier()
        
    if rank == 0:
        print(f"âœ… All samples generated in {output_dir}")
        
    cleanup_ddp()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_dir", type=str, required=True)
    parser.add_argument("--output_dir", type=str, default=None)
    parser.add_argument("--image_size", type=int, default=512)
    parser.add_argument("--total_samples", type=int, default=100)
    parser.add_argument("--batch_size", type=int, default=4)
    parser.add_argument("--steps", type=int, default=1000)
    parser.add_argument("--seed", type=int, default=42)
    
    args = parser.parse_args()
    
    sample_ddpm_ddp(
        model_dir=args.model_dir,
        output_dir=args.output_dir,
        image_size=args.image_size,
        total_samples=args.total_samples,
        batch_size=args.batch_size,
        num_inference_steps=args.steps,
        seed=args.seed
    )
